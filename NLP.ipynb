{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWMAbXHy/b4uBStXr9h9sa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPkyc29SdW2w",
        "outputId": "3bb17248-81b8-4b94-bcb8-33835881b696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "#downloading and importing requirements\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "#giving input text\n",
        "text=\"\"\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome. The sky is pinkish-blue. You shouldn\\'t eat cardboard.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization\n",
        "sent = nltk.sent_tokenize(text)\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSc0GfBzejeZ",
        "outputId": "7927086c-761c-452a-8e08-cadeaeb92ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and city is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the characters like .,?\n",
        "import re\n",
        "print(text.lower())\n",
        "text = re.sub(r'[^a-z\\'A-Z]', \" \",text.lower())\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRGfkJAsesuo",
        "outputId": "47df7fba-2d05-44ae-afc3-623c7b358308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello mr. smith, how are you doing today? the weather is great, and city is awesome. the sky is pinkish-blue. you shouldn't eat cardboard.\n",
            "hello mr  smith  how are you doing today  the weather is great  and city is awesome  the sky is pinkish blue  you shouldn't eat cardboard \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenization\n",
        "#words = text.split()\n",
        "words = nltk.word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WDCnuVSfaVh",
        "outputId": "5f91c832-369b-46b6-8361-093f1f7f667b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'mr', 'smith', 'how', 'are', 'you', 'doing', 'today', 'the', 'weather', 'is', 'great', 'and', 'city', 'is', 'awesome', 'the', 'sky', 'is', 'pinkish', 'blue', 'you', 'should', \"n't\", 'eat', 'cardboard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing stopwords\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words(\"english\"))\n",
        "\n",
        "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiBjT62Fflo5",
        "outputId": "3610dff4-2fc5-4602-ab4f-5b7ffa310aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "['hello', 'mr', 'smith', 'today', 'weather', 'great', 'city', 'awesome', 'sky', 'pinkish', 'blue', \"n't\", 'eat', 'cardboard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmed = [PorterStemmer().stem(w) for w in words]\n",
        "print(stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLGV4H57hL4k",
        "outputId": "e9793828-f03e-4e34-9c00-ac27f39d0e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'mr', 'smith', 'today', 'weather', 'great', 'citi', 'awesom', 'sky', 'pinkish', 'blue', \"n't\", 'eat', 'cardboard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmetization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
        "print(lemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghpfVRvohm4t",
        "outputId": "9e9621e8-bf9f-4334-c1cb-04c9a29c1330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'mr', 'smith', 'today', 'weather', 'great', 'city', 'awesome', 'sky', 'pinkish', 'blue', \"n't\", 'eat', 'cardboard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS tagging\n",
        "from nltk import pos_tag, RegexpParser\n",
        "\n",
        "tagged = pos_tag(lemmed)\n",
        "chunker = RegexpParser('''\n",
        "NP: {} #noun phrases\n",
        "P: {} #pronoun\n",
        "V: {} #verb\n",
        "PP: {} #prepositional phrases\n",
        "VP: {} #verd phrases''')\n",
        "\n",
        "print(tagged)\n",
        "output = chunker.parse(tagged)\n",
        "print('After Extracting: ',output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Q0N7Yni5e8",
        "outputId": "b1e997a9-1f5c-42cb-e3df-276cb8080c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', 'NN'), ('mr', 'NN'), ('smith', 'NN'), ('today', 'NN'), ('weather', 'VBP'), ('great', 'JJ'), ('city', 'NN'), ('awesome', 'VBP'), ('sky', 'JJ'), ('pinkish', 'JJ'), ('blue', 'VBP'), (\"n't\", 'RB'), ('eat', 'VB'), ('cardboard', 'NN')]\n",
            "After Extracting:  (S\n",
            "  hello/NN\n",
            "  mr/NN\n",
            "  smith/NN\n",
            "  today/NN\n",
            "  weather/VBP\n",
            "  great/JJ\n",
            "  city/NN\n",
            "  awesome/VBP\n",
            "  sky/JJ\n",
            "  pinkish/JJ\n",
            "  blue/VBP\n",
            "  n't/RB\n",
            "  eat/VB\n",
            "  cardboard/NN)\n"
          ]
        }
      ]
    }
  ]
}